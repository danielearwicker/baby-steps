\chapter{Summation, Indices and Matrices}

\section{Indices}

An index (plural: indices) is a subscript (and in some contexts a superscript) that stands for an integer.

$$a_n$$

This tells us that $a$ is not just one value, but several. The $n$ can be assumed to take a small range of values such as $1, 2, 3$, the exact size of this range depending on the situation. (In physics if we have a function of integers it's usually written as a set with an index like this, with $f(x)$ reserved for functions of continuous values.)

Instead of labelling spatial coordinates $x, y, z$, we can call them $x_1, x_2, x_3$ and avoid the need to repeat ourselves by just giving the rule for the behaviour of $x_n$, which is then unambiguously the same for all three dimensions of space.

Often we want to add the values:

$$x_1 + x_2 + x_3 + \dots + x_n$$

The shorthand for this is to use the $\Sigma$ symbol:

$$\sum_n{x_n} = x_1 + x_2 + x_3 + \dots + x_n$$

Later this will become so commonplace that we'll adopt an even shorter shorthand.

\section{Vectors and Matrices}

Thinking initially of vectors as mere collections of numbers (a viewpoint which we will rethink in ยง\ref{ch:vectors}), indices give us a way to talk about them. $x_n$ could represent a single row or column of $n$ numbers.

Likewise we can use two indices to label the numbers in a grid or matrix (plural: matrices). Given:

$$
M = \begin{bmatrix}
5 & 2 & 7 \\
0 & 1 & 0 \\
4 & 6 & 8
\end{bmatrix}
$$

We can refer to the elements of $M$ as $M_{ij}$, with $i$ giving the row and $j$ the column. So:

$$M_{32} = 6$$

This unfortunately looks a lot like the number $32$. When it's clear we aren't talking about raising numbers to powers, we use a combination of subscript and superscript indices, with superscripts meaning rows and subscripts meaning columns:

$$M^3_2 = 6$$

\section{Matrix multiplication} \label{sec:matrix-multiplication}

If we're multiplying $A$ and $B$ to get $C$:

$$C = AB$$

in summation notation we can define the cell at row $i$ and column $j$ of $C$ as follows:

$$C^i_j = \sum_k{A^i_kB^k_j}$$

Supposing these are square $3 \times 3$ matrices, so all the $i$, $j$ and $k$ can take the values $1, 2, 3$. Writing out the summation for all values of $k$:

$$C^i_j = A^i_1B^1_j + A^i_2B^2_j + A^i_3B^3_j $$

This turns out to be merely one combination of some more basic operations we'll return to in ยง\ref{ch:tensors}.

\section{Kronecker Delta} \label{def:Kronecker}

This is a compact way of referring to the identity matrix in summations. The diagonal elements are 1, all others are zero, which is awkward to represent in a stretchy way:

$$
\hat{I} = \begin{bmatrix}
1 & 0 & 0 & \dots & 0 \\
0 & 1 & 0 & \dots & 0 \\
0 & 0 & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \dots & 1
\end{bmatrix}
$$

So instead we define the Kronecker delta, which has two indices representing row and column (the order is not important due to the symmetry of the identity matrix):

$$
\delta_{ij} = \begin{cases}
0 &\text{if } i \neq j,   \\
1 &\text{if } i=j.   \end{cases}
$$

